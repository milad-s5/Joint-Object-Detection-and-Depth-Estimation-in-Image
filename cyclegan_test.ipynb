{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf9e300",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ab87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cyclegan.cyclegan import get_resnet_generator, get_discriminator, CycleGan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50ed2e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61837482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac72d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "newpath = r'drive/MyDrive/Colab Notebooks/DL/project' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "os.chdir('drive/MyDrive/Colab Notebooks/DL/project')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c01b5",
   "metadata": {},
   "source": [
    "### Train data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# loading\n",
    "with open('images.npy', 'rb') as f:\n",
    "    images = np.load(f)[:1100]\n",
    "\n",
    "with open('depths.npy', 'rb') as f:\n",
    "    depths = np.expand_dims(np.load(f),axis=3)[:1100]\n",
    "\n",
    "print(images.shape, depths.shape)\n",
    "\n",
    "# Resize\n",
    "ratio = 0.25\n",
    "images = list(images)\n",
    "depths = list(depths)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    images[i] = cv2.resize(images[i],None,fx=ratio,fy=ratio)\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    depths[i] = cv2.resize(depths[i],None,fx=ratio,fy=ratio)\n",
    "\n",
    "images = np.array(images)\n",
    "depths = np.expand_dims(np.array(depths),axis=3)\n",
    "\n",
    "print(images.shape, depths.shape)\n",
    "\n",
    "# normalization\n",
    "images = images / 127.5 - 1\n",
    "depths = depths / 127.5 - 1\n",
    "\n",
    "# TF dataset\n",
    "img_ds = tf.constant(images)\n",
    "dep_ds = tf.constant(depths)\n",
    "img_ds = tf.data.Dataset.from_tensor_slices(img_ds).cache().shuffle(256)\n",
    "img_ds = img_ds.batch(batch_size=1)\n",
    "dep_ds = tf.data.Dataset.from_tensor_slices(dep_ds).cache().shuffle(256)\n",
    "dep_ds = dep_ds.batch(batch_size=1)\n",
    "print(img_ds, dep_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f768e",
   "metadata": {},
   "source": [
    "### Test data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f01efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('images.npy', 'rb') as f:\n",
    "    te_images = np.load(f)[1100:]\n",
    "\n",
    "with open('depths.npy', 'rb') as f:\n",
    "    te_depths = np.expand_dims(np.load(f),axis=3)[1100:]\n",
    "\n",
    "# Resize\n",
    "te_images = list(te_images)\n",
    "te_depths = list(te_depths)\n",
    "for i in range(len(te_images)):\n",
    "    te_images[i] = cv2.resize(te_images[i],None,fx=ratio,fy=ratio)\n",
    "\n",
    "for i in range(len(te_depths)):\n",
    "    te_depths[i] = cv2.resize(te_depths[i],None,fx=ratio,fy=ratio)\n",
    "\n",
    "te_images = np.array(te_images)\n",
    "te_depths = np.expand_dims(np.array(te_depths),axis=3)\n",
    "print (te_images.shape, te_depths.shape)\n",
    "\n",
    "# Normalization\n",
    "te_images = te_images/127.5 - 1\n",
    "te_depths = te_depths/127.5 - 1\n",
    "\n",
    "# TF dataset\n",
    "te_img_ds = tf.constant(te_images)\n",
    "te_dep_ds = tf.constant(te_depths)\n",
    "te_img_ds = tf.data.Dataset.from_tensor_slices(te_img_ds).cache().shuffle(256)\n",
    "te_img_ds = te_img_ds.batch(batch_size=5)\n",
    "te_dep_ds = tf.data.Dataset.from_tensor_slices(te_dep_ds).cache().shuffle(256)\n",
    "te_dep_ds = te_dep_ds.batch(batch_size=5)\n",
    "print (img_ds, dep_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be4bc5",
   "metadata": {},
   "source": [
    "## G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facaacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_X = (120,160,3)\n",
    "size_Y = (120,160,1)\n",
    "\n",
    "# Get the generators\n",
    "gen_G = get_resnet_generator (\n",
    "    filters=48,\n",
    "    num_downsampling_blocks=2,\n",
    "    num_residual_blocks=5,\n",
    "    num_upsample_blocks=2,\n",
    "    name=\"generator_G\",\n",
    "    in_size=size_X,\n",
    "    out_channel=1\n",
    ")\n",
    "\n",
    "gen_F = get_resnet_generator (\n",
    "    filters=48,\n",
    "    num_downsampling_blocks=2,\n",
    "    num_residual_blocks=5,\n",
    "    num_upsample_blocks=2,\n",
    "    name=\"generator_F\",\n",
    "    out_channel=3,\n",
    "    in_size = size_Y\n",
    ")\n",
    "\n",
    "# Get the discriminators\n",
    "disc_X = get_discriminator(\n",
    "    filters=48,\n",
    "    num_downsampling=3,\n",
    "    name = \"discriminator_X\",\n",
    "    in_size = size_X\n",
    ")\n",
    "\n",
    "disc_Y = get_discriminator(\n",
    "    filters=48,\n",
    "    num_downsampling=3,\n",
    "    in_size = size_Y,\n",
    "    name=\"discriminator_Y\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a41e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286d2ed",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
    "\n",
    "    def __init__(self, num_img=4):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
    "        for i, img in enumerate(te_img_ds.take(self.num_img)):\n",
    "            prediction = self.model.gen_G(img)[0].numpy()\n",
    "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "            img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "            ax[i, 0].imshow(img)\n",
    "            ax[i, 1].imshow(prediction.squeeze())\n",
    "            ax[i, 0].set_title(\"Input image\")\n",
    "            ax[i, 1].set_title(\"Translated image\")\n",
    "            ax[i, 0].axis(\"off\")\n",
    "            ax[i, 1].axis(\"off\")\n",
    "\n",
    "            prediction = keras.preprocessing.image.array_to_img(prediction)\n",
    "            prediction.save(\n",
    "                \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1)\n",
    "            )\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4825f",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "\n",
    "# Create cycle gan model\n",
    "cycle_gan_model = CycleGan(\n",
    "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_model.compile(\n",
    "    gen_G_optimizer=keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5),\n",
    "    gen_F_optimizer=keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5),\n",
    "    disc_X_optimizer=keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5),\n",
    "    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5),\n",
    "    gen_loss_fn=generator_loss_fn,\n",
    "    disc_loss_fn=discriminator_loss_fn,\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "plotter = GANMonitor()\n",
    "checkpoint_filepath = \"./model_checkpoints/cyclegan_checkpoints.{epoch:03d}\"\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath\n",
    ")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4706d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((img_ds, dep_ds)),\n",
    "    epochs=10,\n",
    "    callbacks=[plotter]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cf988",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf33bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(5, 3, figsize=(10, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    img = te_images[10*i:10*i+1]\n",
    "    prediction = cycle_gan_model.gen_G(img, training=False)[0]\n",
    "    prediction = (prediction * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "    img = (img[0] * 127.5 + 127.5).astype(np.uint8)\n",
    "    dep = (te_depths[10*i]*127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 1].imshow(prediction.squeeze())\n",
    "    ax[i, 2].imshow(dep.squeeze())\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 2].set_title(\"Actual Depth\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    ax[i, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
